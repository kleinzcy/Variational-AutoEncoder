# Variational-AutoEncoder
VAE and CVAE pytorch implement based on MNIST

# Experiment

I train the VAE with a hidden layer and other parameters are in vae.ipynb

Setting latent dimension to 2, the latent space:

VAE | CVAE
--- | ---
![VAE without conditional](https://github.com/kleinzcy/Variational-AutoEncoder/blob/master/img/latent_space.png) | ![VAE with conditional](https://github.com/kleinzcy/Variational-AutoEncoder/blob/master/img/latent_space_conditional.png)

Sample 10 image:

VAE | CVAE
--- | ---
![VAE without conditional](https://github.com/kleinzcy/Variational-AutoEncoder/blob/master/img/sample.png) | ![VAE with conditional](https://github.com/kleinzcy/Variational-AutoEncoder/blob/master/img/sample-2-True.png)

Setting latent dimension to 8. Sample 10 image:

VAE | CVAE
--- | ---
![VAE without conditional](https://github.com/kleinzcy/Variational-AutoEncoder/blob/master/img/sample-8-False.png) | ![VAE with conditional](https://github.com/kleinzcy/Variational-AutoEncoder/blob/master/img/sample-8-True.png)

# Summary

When the latent dimension is 2, image generated by CVAE is more implict than VAE, because CVAE has label information. And when the latent dimension go higher, the result seem to be bad. I think, when the latent dimension go higher, the complexity of latent space go higher, so the distribution of data is hard to capture. What's more, the latent space sample will confuse the label information when the dimension of latent space is compared able to label dimension.

# Reference

* https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/
* https://ijdykeman.github.io/ml/2016/12/21/cvae.html
* https://zhuanlan.zhihu.com/p/34998569
* https://github.com/timbmg/VAE-CVAE-MNIST
